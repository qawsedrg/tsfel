{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# TSFEL predicting Normal Vs. Pathological knee\n",
    "\n",
    "To perform this example every cell must be executed. To do so click run ([  ]) in the top left of every cell.\n",
    "\n",
    "The first step consists of importing TSFEL library. To do so press play. \n",
    "\n",
    "The import can take few seconds, but the run button will change so that you know that the import has started and ended.\n",
    "\n",
    "A warning will appear to reset all runtimes before running, click to accept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# @title Import Time Series Feature Extraction Library\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "!pip install tsfel >/dev/null 2>&1\n",
    "!pip install patool >/dev/null 2>&1\n",
    "from sys import platform\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    !wget http://archive.ics.uci.edu/ml/machine-learning-databases/00278/SEMG_DB1.rar >/dev/null 2>&1\n",
    "else:\n",
    "    !pip install wget >/dev/null 2>&1\n",
    "    import wget\n",
    "\n",
    "    wget.download(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00278/SEMG_DB1.rar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patoolib\n",
    "import scipy.interpolate as interp\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import tsfel\n",
    "\n",
    "# Unzip dataset\n",
    "patoolib.extract_archive(\"SEMG_DB1.rar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Auxiliary Methods\n",
    "\n",
    "**Data pre-processing**\n",
    "\n",
    "Method to interpolate each file data (EMG and goniometer signals) to the same sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    \"\"\"Interpolating the EMG and goniometer to the same sample size\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data list of pandas DataFrame\n",
    "      EMG and gonomioter signals for a given activity\n",
    "    Returns\n",
    "    -------\n",
    "      Interpolated data (list of nd-array)\n",
    "\n",
    "    \"\"\"\n",
    "    data = [\n",
    "        interp.interp1d(np.arange(len(x[0].dropna())), x[0].dropna(), axis=0, kind=\"nearest\")(\n",
    "            np.linspace(0, len(x[0].dropna()) - 1, len(x[0].iloc[:, 0].dropna()))\n",
    "        )\n",
    "        for x in data\n",
    "    ]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset was acquired by Batallón de sanidad (BASAN) in collaboration with the Universidad Militar Nueva Granada – Bogotá. The protocol was performed by 22 male subjects, 11 with different knee abnormalities previously diagnosed by a professional and other 11 without any known knee pathology. The participants were required to perform 3 different exercises: (1) **walk**, (2) **extension of the leg from the sit position** and (3) **flexion of the knee stand up**.\n",
    "\n",
    "The acquisition process was conducted with 4 electrodes placed on the following muscles (vastus internus, semitendinosus, biceps femoris and rectus femoris) and a goniometer in the knee.\n",
    "\n",
    " \n",
    "**For this example, we will only be using files from the (2) activity and data from rectus femoris muscle and from the goniometer sensor. The classifier will predict if the participant has a normal or pathological knee.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# @title Loading normal and pathological files from extension of the leg from the sit position\n",
    "normal_files = glob.glob(\"*/N_TXT/*.txt\")\n",
    "patholo_files = glob.glob(\"*/A_TXT/*.txt\")\n",
    "\n",
    "normalfl = [\n",
    "    [pd.read_csv(fl, sep=\"\\t\", skiprows=7, usecols=(0, 4), header=None).dropna()] for fl in normal_files if \"Npie\" in fl\n",
    "]\n",
    "\n",
    "patholofl = [\n",
    "    [pd.read_csv(fl, sep=\"\\t\", skiprows=7, usecols=(0, 4), header=None).dropna()]\n",
    "    for fl in patholo_files\n",
    "    if \"Apie\" in fl\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# @title Train and test set\n",
    "# dataset sampling frequency, according to dataset information\n",
    "fs = 1000\n",
    "# window size for window splitter method (each window has 1 seconds)\n",
    "window_size = 1000\n",
    "\n",
    "# Interpolating data\n",
    "normalfl = preprocess(normalfl)\n",
    "patholofl = preprocess(patholofl)\n",
    "\n",
    "# Dividing into train and test sets. Splitting signal in windows\n",
    "# Using 2 normal files and 2 pathological files for test set\n",
    "x_train = list(\n",
    "    itertools.chain(\n",
    "        *[\n",
    "            tsfel.signal_window_splitter(signal[i], window_size, overlap=0)\n",
    "            for signal in [normalfl, patholofl]\n",
    "            for i in range(len(normalfl) - 2)\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "x_test = list(\n",
    "    itertools.chain(\n",
    "        *[\n",
    "            tsfel.signal_window_splitter(signal[i], window_size, overlap=0)\n",
    "            for signal in [normalfl, patholofl]\n",
    "            for i in [len(normalfl) - 2, len(normalfl) - 1]\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "y_train = np.concatenate(\n",
    "    (\n",
    "        np.repeat(\n",
    "            0,\n",
    "            np.cumsum([int(len(normalfl[i]) / window_size) for i in range(len(normalfl) - 2)])[-1],\n",
    "        ),\n",
    "        np.repeat(\n",
    "            1,\n",
    "            np.cumsum([int(len(patholofl[i]) / window_size) for i in range(len(patholofl) - 2)])[-1],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "y_test = np.concatenate(\n",
    "    (\n",
    "        np.repeat(\n",
    "            0,\n",
    "            np.cumsum([int(len(normalfl[i]) / window_size) for i in [len(normalfl) - 2, len(normalfl) - 1]])[-1],\n",
    "        ),\n",
    "        np.repeat(\n",
    "            1,\n",
    "            np.cumsum([int(len(patholofl[i]) / window_size) for i in [len(patholofl) - 2, len(patholofl) - 1]])[-1],\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# @title Visualizing signals\n",
    "nsignal = np.concatenate(x_train[:50])\n",
    "asignal = np.concatenate(x_train[-50:])\n",
    "time = np.linspace(0, len(nsignal) * 1 / fs, len(nsignal))\n",
    "c = [\"orange\", \"seagreen\"]\n",
    "title = [\"Normal knee\", \"Pathological knee\"]\n",
    "\n",
    "for i, signal in enumerate([nsignal, asignal]):\n",
    "    plt.figure(i)\n",
    "    plt.subplot(211)\n",
    "    plt.plot(time, signal[:, 0], color=c[i], label=\"rectus femoris (mv)\")\n",
    "    plt.legend()\n",
    "    plt.subplot(212)\n",
    "    plt.plot(time, signal[:, 1], color=c[i], label=\"goniometer (degree)\")\n",
    "    plt.legend()\n",
    "    plt.suptitle(title[i])\n",
    "\n",
    "    plt.xlabel(\"Time (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Extract all features' domains (spectral, statistical and temporal)\n",
    "cfg_file = tsfel.get_features_by_domain()\n",
    "X_train = tsfel.time_series_features_extractor(cfg_file, x_train, fs=fs, header_names=np.array([\"emg\", \"gon\"]))\n",
    "X_test = tsfel.time_series_features_extractor(cfg_file, x_test, fs=fs, header_names=np.array([\"emg\", \"gon\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "After the sensor data is extracted, redundancies and noise should be removed. Thus, minimising the algorithm's error, time and computational complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Highly correlated features are removed\n",
    "corr_features, X_train = tsfel.correlated_features(X_train, drop_correlated=True)\n",
    "X_test.drop(corr_features, axis=1, inplace=True)\n",
    "\n",
    "# Remove low variance features\n",
    "selector = VarianceThreshold()\n",
    "X_train = selector.fit_transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Normalising Features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "nX_train = scaler.fit_transform(X_train)\n",
    "nX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Classification\n",
    "\n",
    "In this example the classification is performed with a [Decision Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(nX_train, y_train.ravel())\n",
    "\n",
    "# Predict on test data\n",
    "y_predict = classifier.predict(nX_test)\n",
    "\n",
    "condition_labels = [\"Normal\", \"Pathological\"]\n",
    "\n",
    "# Get the classification report\n",
    "accuracy = accuracy_score(y_test, y_predict) * 100\n",
    "print(classification_report(y_test, y_predict, target_names=condition_labels))\n",
    "print(\"Accuracy: \" + str(accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# @title Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "df_cm = pd.DataFrame(cm, index=[i for i in condition_labels], columns=[i for i in condition_labels])\n",
    "plt.figure()\n",
    "ax = sns.heatmap(df_cm, cbar=True, cmap=\"BuGn\", annot=True, fmt=\"d\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.ylabel(\"True label\", fontweight=\"bold\", fontsize=18)\n",
    "plt.xlabel(\"Predicted label\", fontweight=\"bold\", fontsize=18)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "All features domains were used in the feature extraction step. Accordingly, the Decision Tree classifier obtained high accuracy and was able to distinguish between normal and pathological knee condition during the extension of the leg from the sit position activity."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
