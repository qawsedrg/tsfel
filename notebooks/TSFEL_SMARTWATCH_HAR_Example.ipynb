{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Smartwatch Activity Recognition using TSFEL\n",
    "\n",
    "On this example we will perform Human Activty Recognition using our library **Time Series Feature Extraction Library**.\n",
    "\n",
    "To perform this example every cell must be executed. To do so click run ([  ]) in the top left of every cell.\n",
    "\n",
    "The first step consists on importing the library. To do that press play. \n",
    "\n",
    "The import can take a few seconds, but the run button will change so that you know the import has started and ended.\n",
    "\n",
    "A warning will appear to reset all runtimes before running, click to accept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Import Time Series Feature Extraction Library\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "!pip install tsfel >/dev/null 2>&1\n",
    "from sys import platform\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    !wget http://archive.ics.uci.edu/ml/machine-learning-databases/00507/wisdm-dataset.zip >/dev/null 2>&1\n",
    "else:\n",
    "    !pip install wget >/dev/null 2>&1\n",
    "    import wget\n",
    "\n",
    "    wget.download(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00507/wisdm-dataset.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "To check if everything was correctly imported, access \"Files\" (on the left side of the screen) and press \"Refresh\". If UCI HAR Dataset folder does not appear run Import Time Series Features library again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import glob\n",
    "import itertools\n",
    "import secrets\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import interpolate\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import tsfel\n",
    "\n",
    "# Unzip dataset\n",
    "zip_ref = zipfile.ZipFile(\"wisdm-dataset.zip\", \"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Auxiliary Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Data pre-processing**\n",
    "\n",
    "Method to interpolate accelerometer and gyroscope data to the same time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def pre_process_data(data_acc, data_gyro, fs):\n",
    "    \"\"\"This function interpolates the accelerometer and gyroscope data to\n",
    "    the same time interval.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_acc nd-array\n",
    "    Accelerometer data of specified activity\n",
    "    data_gyro nd-array\n",
    "    Gyroscope data of specified activity\n",
    "    fs int\n",
    "    Sampling frequency\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Interpolated data (nd-array)\n",
    "\n",
    "    \"\"\"\n",
    "    time_acc = (data_acc[:, 2]) / 1e9 - data_acc[0, 2] / 1e9\n",
    "    data_act_acc = data_acc[:, 3:]\n",
    "\n",
    "    time_gyro = (data_gyro[:, 2]) / 1e9 - data_gyro[0, 2] / 1e9\n",
    "    data_act_gyro = data_gyro[:, 3:]\n",
    "\n",
    "    # time interval for interpolation\n",
    "    t0 = np.max([time_acc[0], time_gyro[0]])\n",
    "    tn = np.min([time_acc[-1], time_gyro[-1]])\n",
    "    time_new = np.linspace(t0, tn, int((tn - t0) / (1 / fs)))\n",
    "\n",
    "    # interpolation\n",
    "    acc_data = np.array(\n",
    "        [interpolate.interp1d(time_acc, data_act_acc[:, ax])(time_new) for ax in range(np.shape(data_act_acc)[1])]\n",
    "    ).T\n",
    "    gyro_data = np.array(\n",
    "        [interpolate.interp1d(time_gyro, data_act_gyro[:, ax])(time_new) for ax in range(np.shape(data_act_gyro)[1])]\n",
    "    ).T\n",
    "\n",
    "    # concatenate interpolated data\n",
    "    data = np.concatenate((acc_data, gyro_data), axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "The dataset we will be using is open-source. It is provided by UCI and it was performed by 51 subjects using a smartphone on their pocket and a smartwatch on their dominant hand. It contains a total of 18 activities whose labels are given by the following letters:\n",
    "\n",
    "* Walking = A\n",
    "* Jogging = B\n",
    "* Stairs = C\n",
    "* Sitting = D\n",
    "* Standing = E\n",
    "* Typing = F\n",
    "* Brushing Teeth = G\n",
    "* Eating Soup = H\n",
    "* Eating Chips = I\n",
    "* Eating Pasta = J\n",
    "* Drinking from Cup = K\n",
    "* Eating Sandwich = L\n",
    "* Kicking Soccer Ball = M\n",
    "* Playing Catch w/Tennis Ball = O\n",
    "* Dribblinlg Basketball = P\n",
    "* Writing = Q\n",
    "* Clapping = R\n",
    "* Folding Clothes = S\n",
    "\n",
    "For this classification problem only the smartwatch data will be used.\n",
    "\n",
    "The dataset used in this example can be found [here](https://archive.ics.uci.edu/ml/datasets/WISDM+Smartphone+and+Smartwatch+Activity+and+Biometrics+Dataset+)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Load Data\n",
    "\n",
    "Files from accelerometer and gyroscope of the smartwatch will be loaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Loading smartwatch data files\n",
    "watch_files_acc = np.sort(glob.glob(\"wisdm-dataset/raw/watch/accel\" + \"*/**.txt\", recursive=True))\n",
    "watch_files_gyro = np.sort(glob.glob(\"wisdm-dataset/raw/watch/gyro\" + \"*/**.txt\", recursive=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Defining train and test\n",
    "\n",
    "Data will be splitted into equal sized windows according to the performed activity.\n",
    "\n",
    "Train and Test sets will be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "all_acc_data = [\n",
    "    np.array(pd.read_csv(acc_file, header=None, delimiter=\",\", comment=\";\")) for acc_file in watch_files_acc\n",
    "]\n",
    "all_gyro_data = [\n",
    "    np.array(pd.read_csv(gyro_file, header=None, delimiter=\",\", comment=\";\")) for gyro_file in watch_files_gyro\n",
    "]\n",
    "\n",
    "x_test = []\n",
    "x_train = []\n",
    "y_test = []\n",
    "y_train = []\n",
    "activities = np.unique(np.vstack(all_acc_data)[:, 1]).astype(str)\n",
    "ntrain = 45\n",
    "fs = 20  # According to dataset information\n",
    "overlap = 0\n",
    "ws = 200  # 10 second windows\n",
    "\n",
    "for acq, (acc_data, gyro_data) in enumerate(zip(all_acc_data, all_gyro_data)):\n",
    "    windows = []\n",
    "    labels = []\n",
    "\n",
    "    for act in activities:\n",
    "        act_acc, act_gyro = np.where(acc_data == act)[0], np.where(gyro_data == act)[0]\n",
    "        acc_data_act, gyro_data_act = acc_data[act_acc, :], gyro_data[act_gyro, :]\n",
    "        ids_act_acc = np.append(0, np.where(np.diff(act_acc) > 1)[0] + 1)\n",
    "        ids_act_gyro = np.append(0, np.where(np.diff(act_gyro) > 1)[0] + 1)\n",
    "\n",
    "        if len(act_acc) == 0 or len(act_gyro) == 0:\n",
    "            continue\n",
    "\n",
    "        # Only one acquisition of act\n",
    "        if (len(ids_act_gyro) == 1) and (len(ids_act_acc) == 1):\n",
    "            data = pre_process_data(acc_data_act, gyro_data_act, fs)\n",
    "            w = tsfel.signal_window_splitter(data.astype(float), ws, overlap)\n",
    "            windows.append(w)\n",
    "            labels.append(np.repeat(act, len(w)))\n",
    "        else:\n",
    "            # More than one acquisition of act\n",
    "            acc_data_acts = [acc_data_act[ids_act_acc[i] : ids_act_acc[i + 1], :] for i in range(len(ids_act_acc) - 1)]\n",
    "            gyro_data_acts = [\n",
    "                gyro_data_act[ids_act_gyro[i] : ids_act_gyro[i + 1], :] for i in range(len(ids_act_gyro) - 1)\n",
    "            ]\n",
    "\n",
    "            for acc_data_act, gyro_data_act in zip(acc_data_acts, gyro_data_acts):\n",
    "                data = pre_process_data(acc_data_act, gyro_data_act, fs)\n",
    "                w = tsfel.signal_window_splitter(data.astype(float), ws, overlap)\n",
    "                windows.append(w)\n",
    "                labels.append(np.repeat(act, len(w)))\n",
    "\n",
    "    # Consider ntrain acquisitions for train and the remaining for test\n",
    "    if acq <= ntrain:\n",
    "        x_train.append(windows)\n",
    "        y_train.append(np.hstack(labels))\n",
    "    else:\n",
    "        x_test.append(windows)\n",
    "        y_test.append(np.hstack(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "y_train = np.hstack(y_train)\n",
    "y_test = np.hstack(y_test)\n",
    "x_train = list(itertools.chain(*list(itertools.chain(*x_train))))\n",
    "x_test = list(itertools.chain(*list(itertools.chain(*x_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Feature Extraction\n",
    "\n",
    "Through **Feature Extraction** methodologies, the data is translated into a feature vecture containing information about the signal properties of each window. These properties can be classifier according to their domain as Time, Frequency and Statistical features and allow to characterise the signal in a compact way, enhancing its chracteristics.\n",
    "\n",
    "In this classification problem only features from the temporal domain will be used as input to the machine learning classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "cfg_file = tsfel.get_features_by_domain(\"temporal\")\n",
    "x_train_feat = tsfel.time_series_features_extractor(\n",
    "    cfg_file,\n",
    "    x_train,\n",
    "    fs=fs,\n",
    "    header_names=[\"accx\", \"accy\", \"accz\", \"gyrox\", \"gyroy\", \"gyroz\"],\n",
    ")\n",
    "x_test_feat = tsfel.time_series_features_extractor(\n",
    "    cfg_file,\n",
    "    x_test,\n",
    "    fs=fs,\n",
    "    header_names=[\"accx\", \"accy\", \"accz\", \"gyrox\", \"gyroy\", \"gyroz\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Feature Selection\n",
    "\n",
    "After the sensor data is extracted, redundancies and noise should be removed. Thus, minimising the algorithm's error, time and computational complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly correlated features are removed\n",
    "corr_features, x_train_feat = tsfel.correlated_features(x_train_feat, drop_correlated=True)\n",
    "x_test_feat.drop(corr_features, axis=1, inplace=True)\n",
    "\n",
    "# Remove low variance features\n",
    "selector = VarianceThreshold()\n",
    "X_train = selector.fit_transform(x_train_feat)\n",
    "X_test = selector.transform(x_test_feat)\n",
    "\n",
    "# Normalising Features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "nX_train = scaler.fit_transform(X_train)\n",
    "nX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Classification\n",
    "\n",
    "In this example the classification is performed with a [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=20, min_samples_split=10)\n",
    "\n",
    "activities = [\n",
    "    \"walking\",\n",
    "    \"jogging\",\n",
    "    \"stairs\",\n",
    "    \"sitting\",\n",
    "    \"standing\",\n",
    "    \"typing\",\n",
    "    \"brushing teeth\",\n",
    "    \"eating soup\",\n",
    "    \"eating chips\",\n",
    "    \"eating pasta\",\n",
    "    \"drinking\",\n",
    "    \"eating sandwich\",\n",
    "    \"kicking\",\n",
    "    \"playing catch\",\n",
    "    \"dribblinlg\",\n",
    "    \"writing\",\n",
    "    \"clapping\",\n",
    "    \"folding clothes\",\n",
    "]\n",
    "\n",
    "# Train The Classifier\n",
    "classifier.fit(X_train, y_train.ravel())\n",
    "\n",
    "# Predict Test Data\n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "# Get the Classification Report\n",
    "accuracy = accuracy_score(y_test, y_predict) * 100\n",
    "print(classification_report(y_test, y_predict, target_names=activities))\n",
    "print(\"Accuracy: \" + str(accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_predict)\n",
    "df_cm = pd.DataFrame(cm, index=[i for i in activities], columns=[i for i in activities])\n",
    "plt.figure()\n",
    "ax = sns.heatmap(df_cm, cbar=True, cmap=\"BuGn\", annot=True, fmt=\"d\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "plt.ylabel(\"True label\", fontweight=\"bold\", fontsize=18)\n",
    "plt.xlabel(\"Predicted label\", fontweight=\"bold\", fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "The final accuracy obtained by feeding a Random Forest classifier with only temporal domain features is around 75%.   \n",
    "\n",
    "As it can be seen in the confusion matrix, eating chips activity is the class with more misclassified samples. This activity is being mainly classified as eating sandwich activity, which is reasonable since both activities rely almost on the same hand movement.\n",
    "\n",
    "Although the overall results are satisfying, the increase of the classifier performance may be achieved by extracting features from all domains (temporal, statistical and spectral) and by including smartphone's data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
