{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Human Activity Recognition using TSFEL\n",
    "\n",
    "On this example, we will perform Human Activity Recognition using our library **Time Series Feature Extraction Library**.\n",
    "\n",
    "To perform this example every cell must be executed. To do so click run ([  ]) in the top left of every cell.\n",
    "\n",
    "The first step consists of importing the library. To do that press play. \n",
    "\n",
    "The import can take a few seconds, but the run button will change so that you know the import has started and ended.\n",
    "\n",
    "A warning will appear to reset all runtimes before running, click to accept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# @title Import Time Series Feature Extraction Library\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "!pip install tsfel >/dev/null 2>&1\n",
    "from sys import platform\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    !wget http://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip >/dev/null 2>&1\n",
    "else:\n",
    "    !pip install wget >/dev/null 2>&1\n",
    "    import wget\n",
    "\n",
    "    wget.download(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI HAR Dataset.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "To check if everything was correctly imported, access \"Files\" (on the left side of the screen) and press \"Refresh\". If UCI HAR Dataset folder does not appear run Import Time Series Features library again.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Import libraries\n",
    "import tsfel\n",
    "\n",
    "sns.set()\n",
    "\n",
    "# Unzip dataset\n",
    "zip_ref = zipfile.ZipFile(\"UCI HAR Dataset.zip\", \"r\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "The dataset we will be using is open-source. It is provided by UCI and it was performed by 30 volunteers using a smartphone on the waist. It contains 6 activities: \n",
    "\n",
    "*   Walking\n",
    "*   Standing\n",
    "*   Sitting\n",
    "*   Laying\n",
    "*   Upstairs\n",
    "*   Downstairs\n",
    "\n",
    "The dataset used in this example can be found [here](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# @title Data Preparation\n",
    "\n",
    "# Load data\n",
    "x_train_sig = list(np.loadtxt(\"UCI HAR Dataset/train/Inertial Signals/total_acc_x_train.txt\", dtype=\"float32\"))\n",
    "x_test_sig = list(np.loadtxt(\"UCI HAR Dataset/test/Inertial Signals/total_acc_x_test.txt\", dtype=\"float32\"))\n",
    "y_test = np.loadtxt(\"UCI HAR Dataset/test/y_test.txt\")\n",
    "y_train = np.loadtxt(\"UCI HAR Dataset/train/y_train.txt\")\n",
    "activity_labels = np.array(pd.read_csv(\"UCI HAR Dataset/activity_labels.txt\", header=None, delimiter=\" \"))[:, 1]\n",
    "\n",
    "# dataset sampling frequency\n",
    "fs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# @title Signal Preview\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt_size = 10\n",
    "plt.plot(np.concatenate(x_train_sig[0:plt_size], axis=0))\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"Acceleration (m/sÂ²)\")\n",
    "plt.title(\"Accelerometer Signal\")\n",
    "plt.legend(\"x axis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Feature Extraction\n",
    "\n",
    "Through **Feature Extraction** methodologies, the data is translated into a feature vector containing information about the signal properties of each window. These properties can be classified according to their domain as Time, Frequency and Statistical features and allow to characterise the signal compactly, enhancing its characteristics. This features will be used as input to the machine learning classifier, thus, the chosen set of features can strongly influence the classification output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# @title Feature Extraction\n",
    "cfg_file = tsfel.get_features_by_domain()  # All features\n",
    "# cfg_file = tsfel.get_features_by_domain('statistical') # Only statistical features\n",
    "# cfg_file = tsfel.get_features_by_domain('temporal')    # Only temporal features\n",
    "# cfg_file = tsfel.get_features_by_domain('spectral')    # Only spectral features\n",
    "\n",
    "# Get features\n",
    "X_train = tsfel.time_series_features_extractor(cfg_file, x_train_sig, fs=fs)\n",
    "X_test = tsfel.time_series_features_extractor(cfg_file, x_test_sig, fs=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Feature Selection\n",
    "\n",
    "After the sensor data is extracted, redundancies and noise should be removed. Thus, minimising the algorithm's error, time and computational complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# Highly correlated features are removed\n",
    "corr_features, X_train = tsfel.correlated_features(X_train, drop_correlated=True)\n",
    "X_test.drop(corr_features, axis=1, inplace=True)\n",
    "\n",
    "# Remove low variance features\n",
    "selector = VarianceThreshold()\n",
    "X_train = selector.fit_transform(X_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# Normalising Features\n",
    "scaler = preprocessing.StandardScaler()\n",
    "nX_train = scaler.fit_transform(X_train)\n",
    "nX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Classification\n",
    "\n",
    "In this example the classification is performed with a [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier()\n",
    "# Train the classifier\n",
    "classifier.fit(nX_train, y_train.ravel())\n",
    "\n",
    "# Predict test data\n",
    "y_test_predict = classifier.predict(nX_test)\n",
    "\n",
    "# Get the classification report\n",
    "accuracy = accuracy_score(y_test, y_test_predict) * 100\n",
    "print(classification_report(y_test, y_test_predict, target_names=activity_labels))\n",
    "print(\"Accuracy: \" + str(accuracy) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "# @title Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_predict)\n",
    "df_cm = pd.DataFrame(cm, index=[i for i in activity_labels], columns=[i for i in activity_labels])\n",
    "plt.figure()\n",
    "ax = sns.heatmap(df_cm, cbar=False, cmap=\"BuGn\", annot=True, fmt=\"d\")\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.ylabel(\"True label\", fontweight=\"bold\", fontsize=18)\n",
    "plt.xlabel(\"Predicted label\", fontweight=\"bold\", fontsize=18)\n",
    "bottom, top = ax.get_ylim()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "As it can be seen in the confusion matrix, the misclassification was higher between WALKING UPSTAIRS vs WALKING DOWNSTAIRS vs WALKING and SITTING vs STANDING. Dynamic activities, due to their distinct motion characteristics and cyclic behaviour, were clearly discriminated against static activities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tsfel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
